# Text Summarization

## Metrics for assessing summarization algorithms/models

- Kryściński, Wojciech, et al. [Evaluating the Factual Consistency of Abstractive Text Summarization](https://arxiv.org/pdf/1910.12840.pdf). Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020. [Code](https://github.com/salesforce/factCC)

- Fabbri, Alexander R., et al. [SummEval: Re-evaluating Summarization Evaluation](https://arxiv.org/pdf/2007.12626.pdf). Transactions of the Association for Computational Linguistics (TACL), 2021. [Code](https://github.com/Yale-LILY/SummEval)

- Wang, Alex, Kyunghyun Cho, and Mike Lewis. [Asking and Answering Questions to Evaluate the Factual Consistency of Summaries](https://arxiv.org/pdf/2004.04228.pdf). Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), 2020. [Code](https://github.com/W4ngatang/qags)

- Zhang, Yuhao, et al. [Optimizing the Factual Correctness of a Summary:
A Study of Summarizing Radiology Reports](https://arxiv.org/pdf/1911.02541.pdf). Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), 2020.

- Xu, Jiacheng, Shrey Desai, and Greg Durrett. [Understanding Neural Abstractive Summarization Models via Uncertainty](https://arxiv.org/pdf/2010.07882.pdf). Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020. [Code](https://github.com/jiacheng-xu/text-sum-uncertainty)


- Cao, Meng, et al. [Factual Error Correction for Abstractive Summarization Models](https://arxiv.org/pdf/2010.08712.pdf). Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020. [Code](https://github.com/mcao516/Factual-Error-Correction)

- Dou, Zi-Yi, et al. [GSum: A General Framework for Guided Neural Abstractive Summarization](https://arxiv.org/pdf/2010.08014.pdf). Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2021. [Code](https://github.com/neulab/guided_summarization)

- Rahul, Shashi et al.[Focus Attention: Promoting Faithfulness and Diversity in Summarization](https://arxiv.org/pdf/2105.11921.pdf). manuscript, 2021

- Elazar, Yanai, et al. [Measuring and improving consistency in pretrained language models](https://arxiv.org/pdf/2102.01017.pdf). Transactions of the Association for Computational Linguistics (TACL), 2021. [Code](https://github.com/yanaiela/pararel)

- Pagnoni, Artidoro, Vidhisha Balachandran, and Yulia Tsvetkov. [Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics](https://arxiv.org/pdf/2104.13346.pdf). Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL), 2021. [Code](https://github.com/artidoro/frank)

- Ladhak, Faisal, et al. [Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization](https://arxiv.org/pdf/2108.13684.pdf). arXiv preprint, 2020. 

- Xu, Jiacheng, and Greg Durrett. [Dissecting generation modes for abstractive summarization models via ablation and attribution](https://arxiv.org/pdf/2106.01518.pdf).arXiv preprint, 2021. [Code](https://github.com/jiacheng-xu/sum-interpret) 


## Summarization algorithms/models

- Nallapati, Ramesh, et al. [Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond](https://arxiv.org/abs/1602.06023). Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning. 2016. [Code(Non-official)](https://github.com/theamrzaki/text_summurization_abstractive_methods)

- Zhang, Jingqing, et al. [Pegasus: Pre-training with extracted gap-sentences for abstractive summarization](http://proceedings.mlr.press/v119/zhang20ae/zhang20ae.pdf). International Conference on Machine Learning. PMLR, 2020. [Code](https://github.com/google-research/pegasus) 

- Salemi, Alireza, et al. [ARMAN: Pre-training with Semantically Selecting and Reordering of Sentences for Persian Abstractive Summarization.](https://arxiv.org/abs/2109.04098). arXiv preprint, 2021.

- Rothe, Sascha, Shashi Narayan, and Aliaksei Severyn. [Leveraging pre-trained checkpoints for sequence generation tasks](https://arxiv.org/pdf/1907.12461.pdf). Transactions of the Association for Computational Linguistics 8 (2020): 264-280. [Code](https://github.com/google-research/google-research/tree/master/bertseq2seq)

- Huang, Luyang, et al. [Efficient Attentions for Long Document Summarization](https://arxiv.org/pdf/2104.02112.pdf). Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL), 2021. [Code](https://github.com/luyang-huang96/LongDocSum)

- Zhu, Chenguang, et al. [Enhancing Factual Consistency of Abstractive Summarization](https://arxiv.org/pdf/2003.08612.pdf). Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL). 2021. [Code](https://github.com/zcgzcgzcg1/FASum/)

## Survery

- Shi, Tian, et al. [Neural abstractive text summarization with sequence-to-sequence models.](https://dl.acm.org/doi/pdf/10.1145/3419106). ACM Transactions on Data Science 2.1 (2021): 1-37.


- Celikyilmaz, Asli, Elizabeth Clark, and Jianfeng Gao. [Evaluation of Text Generation: A Survey](https://arxiv.org/pdf/2006.14799.pdf). arXiv preprint,2020

- Gehrmann, Sebastian, et al. [The gem benchmark: Natural language generation, its evaluation and metrics](https://arxiv.org/pdf/2102.01672.pdf). Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM), 2021. 


## Dataset

- Narayan, Shashi, Shay B. Cohen, and Mirella Lapata. [Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization](https://arxiv.org/pdf/1808.08745.pdf). Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2018. [Code](https://github.com/EdinburghNLP/XSum)

- Maynez, Joshua, Shashi Narayan and Bernd Bohnet and Ryan Thomas Mcdonald [On Faithfulness and Factuality in Abstractive Summarization](https://arxiv.org/abs/2005.00661). Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 2020. [Code](https://github.com/google-research-datasets/xsum_hallucination_annotations)

- [CNN-Daily](https://github.com/harvardnlp/sent-summary)

- [Gigaword](https://github.com/harvardnlp/sent-summary)

- [SAMSum](https://huggingface.co/datasets/samsum)
